
# ______________________________________________________________________________________________________
# Import des biblioth√®ques
# ______________________________________________________________________________________________________

import streamlit as st
import pandas as pd
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

from sklearn.metrics import accuracy_score, plot_confusion_matrix, roc_curve, roc_auc_score, auc, precision_score, recall_score, classification_report
from sklearn import linear_model, neighbors, svm, tree, ensemble
from sklearn.model_selection import GridSearchCV, train_test_split

# ______________________________________________________________________________________________________
# Configuration du site
# ______________________________________________________________________________________________________

st.set_page_config(page_title="JAD'Up",  layout='wide', page_icon='https://raw.githubusercontent.com/amelievert/streamlit-example/master/Agence%20de%20Marketing.ico')

st.sidebar.title("Sommaire")
st.sidebar.image('https://raw.githubusercontent.com/amelievert/streamlit-example/master/Agence%20de%20Marketing.ico')

pages = ["Introduction au jeu de donn√©es",
         "Analyse",
         "Preprocessing",
         "Challenge de mod√®les",
         "Pour aller plus loin"]

page = st.sidebar.radio("Aller vers", pages) 


# ______________________________________________________________________________________________________
# Import du jeu de donn√©es
# ______________________________________________________________________________________________________

df = pd.read_csv('bank.csv', sep = ',')

# ______________________________________________________________________________________________________
# Pr√©paration des jeux de donn√©es √† utiliser
# ______________________________________________________________________________________________________

df2 = df.copy()

# Creation de tranches d'√¢ges
df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])

# Creation de tranches de solde compte bancaire = balance
df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])

# Creation de tranches de dur√©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

# Creation de tranches de dur√©e de contact = duration
df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

# Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts
df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

# Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non
df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')

# Cr√©ation de tranches en fonction du d√©lai √©coul√©
df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])

# Creation de tranches de nombre de contact avant la campagne
df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

# Suppression des colonnes dummies"√©es"
drop_cols=['age','balance','duration','campaign','pdays','previous']
df2 = df2.drop(drop_cols, axis=1)

# Cr√©ation de dummies
var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
df2= df2.join(pd.get_dummies(df2[var], prefix=var))
df2 = df2.drop(df2[var], axis=1)

# Transformation en num√©rique
le = LabelEncoder()
df2['job2']= le.fit_transform(df2['job'])
df2 = df2.drop(['job'], axis=1)

# Remplace yes/no par 1/0
var = ["default", "housing","loan","deposit","contact_last_campaign"]
df2[var] = df2[var].replace(('yes', 'no'), (1, 0))

# ---------- Fonction de description -----------

def describe_df(df):
    """
    Fonction am√©lior√©e de description des colonnes, elle permet d'identifier :
    le type de la colonne , le nb de valeur vide (nan), le nb de valeurs uniques, le pourcentage de r√©partition des valeurs
    INPUT : le dataframe
    OUTPUT : tableau d'analyse
    """
    res = pd.DataFrame(index=["Name","Type", "Nan", "Unique","Min","Max","Values","Pourcentage"])
    for col in df.columns:
        df_col = df[col]
        res[col] = [
            df_col.name,
            df_col.dtype,
            df_col.isnull().sum(),
            len(df_col.unique()),
            df_col.min(),
            df_col.max(),
            df_col.unique(),
            (df_col.value_counts(ascending=False, normalize=True) * 100)
                .apply(int)
                .to_json(),
        ]
    return res.T


# ______________________________________________________________________________________________________
# 1/ Introduction au jeu de donn√©es
# ______________________________________________________________________________________________________

if page==pages[0]: 

  st.title("Description du jeu de donn√©es")

  st.markdown(
           "Ce jeu de donn√©es est compos√© de donn√©es personnelles sur des clients d‚Äôune banque qui ont √©t√© ‚Äút√©l√©market√©s‚Äù pour souscrire √† un produit "
           "que l‚Äôon appelle un 'd√©p√¥t √† terme'. "
           "Lorsqu‚Äôun client souscrit √† ce produit, il place une quantit√© d‚Äôargent dans un compte sp√©cifique et ne pourra pas toucher ces fonds avant l‚Äôexpiration "
           "du terme."
           "En √©change, le client re√ßoit des int√©r√™ts de la part de la banque √† la fin du terme.  \n" 
           "Le jeu de donn√©es est t√©l√©chargeable au lien suivant :"
           "https://www.kaggle.com/janiobachmann/bank-marketing-dataset")
         
# ---------- Les chiffres cl√©s -----------

  st.header("Les chiffres cl√©s :")
  col1, col2, col3, col4, col5 = st.columns(5)
  col1.write('')
  col2.metric("Nombre de clients", "11 162")
  col3.metric("Nombre de features", "17")
  col4.metric("Proportion des cibles", "47%")
  col5.write('')
         
# ---------- les variables  -----------

  st.header("Description des variables :")         
  st.image("Describe.png")

  #var = pd.DataFrame({"Nom des variables": ["age","job","marital","education","default","balance","housing","loan","contact","day","month","duration","campaign","pdays","previous","poutcome","deposit"],
  #  "Description": ["Age du client","Profession","Statut marital","Niveau d'√©tudes","D√©faut de paiement","Solde du compte","Pr√™t immo","Pr√™t perso",
  #  "Type de contact","Dernier jour de contact","Dernier mois de  contact","Dur√©e du contact (secondes)","Nombre de contacts","Nb jours √©coul√©s depuis le dernier contact","Nb de contacts",
  #  "R√©sultat de la campagne pr√©c√©dente","R√©sultat de la campagne en cours"]
  #  })

  #st.write(var)

# ---------- Aper√ßu -----------

  describe = st.checkbox("Aper√ßu du jeu de donn√©es")
  if describe:
    st.write(df)

# ---------- Ce qu'il faut comprendre -----------

  st.header("Ce qu'il faut retenir :")
  st.markdown(
           "On remarque que certaines variables sont la r√©sultante de la campagne en cours : \n"
           "* contact \n"
           "* day \n"
           "* month \n"
           "* duration \n"
           "* campaign \n"
           "La variable **deposit** est notre variable cible.")
         
# ______________________________________________________________________________________________________
# 2/ Analyse du jeu de donn√©es
# ______________________________________________________________________________________________________

if page==pages[1]: 

  st.title("Analyse du jeu de donn√©es")
  st.markdown(
           "L‚Äôanalyse descriptive est le terme donn√© √† l‚Äôanalyse des donn√©es permettant de d√©crire et de r√©sumer des donn√©es historiques de mani√®re significative "
           "afin que des **insights** en ressortent.\n"
           "L‚Äôanalyse descriptive de notre jeu de donn√©es va nous fournir les informations de base sur les variables, leur r√©partition, et leurs relations potentielles. \n"
           "Nous allons pouvoir observer - _√† premi√®re vue_ - les √©l√©ments qui ont favoris√©, ou √† l'inverse d√©favoris√©, la performance de la campagne commerciale.")

# ---------- Les distributions par type de variables -----------

  st.subheader("Les distributions par type de variables")
         
  col1, col2 = st.columns(2)
  col1.subheader("Variables num√©riques")
  col2.subheader("Variables cat√©gorielles")
  df2 = df.copy()
  numerics = df2.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns
  categoricals= df2.select_dtypes(include=['object','category']).columns

# variables num√©riques

  tab1, tab2 = col1.tabs(["üìà Chart", "üìã Describe"])
         
  option = tab1.selectbox("Choix une variable num√©rique :",numerics)
  hist = px.histogram(df2,x=option,color="deposit",barmode="group")
  tab1.plotly_chart(hist)
         
  describe= df2[numerics].describe().transpose()
  tab2.write(describe)

  if option=="age":
    col1.write("Les √¢ges extr√™mes semblent avoir une plus forte adh√©rence avec la campagne.")
  elif option=="balance":
    col1.write("RAS")
  elif option=="day":
    col1.write("RAS")
  elif option=="duration":
    col1.write("On remarque que plus la dur√©e de contact augmente et plus les clients semblent souscrire √† la campagne.")
  elif option=="campaign":
    col1.write("RAS")
  elif option=="pdays":
    col1.write("RAS")
  elif option=="previous":
    col1.write("RAS")

# variables cat√©gorielles

  tab3, tab4 = col2.tabs(["üìà Chart", "üìã Describe"])

  option = tab3.selectbox("Choix une variable cat√©gorielle :", categoricals)
  hist = px.histogram(df2,y=option,color="deposit",barmode="group")
  tab3.plotly_chart(hist)
         
  describe= df2[categoricals].describe().transpose()
  tab4.write(describe)


# ---------- Les correlations -----------

  st.header("Analyse des corr√©lations")
  tab1, tab2 = st.tabs(["‚ñ© Matrice", "üìà Chart"])
         
# Matrice de correlation

  col1, col2 = tab1.columns((2, 1))

  le = LabelEncoder()
  df2=df.copy()
  for col in df2.columns:
    df2[col]= le.fit_transform(df2[col])
  
  fig = plt.figure(figsize=(15,10))
  sns.heatmap(df2.corr(), annot=True, cmap='RdBu_r', center=0)
  col1.pyplot(fig)
  col2.write('')

# Corr√©lations directes

  col3, col4 = tab2.columns((3, 1))

  corr=pd.DataFrame(df2.corr()["deposit"])
  corr=corr.sort_values("deposit",ascending=False, key=abs)
         
  fig = plt.figure(figsize=(10,5))
  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='bar', cmap='viridis')
  col3.pyplot(fig)

# Corr√©lations coefficients

  coef=df2.corr()["deposit"]
  col4.write(coef)


# ---------- Les observations -----------

  st.header("Observations")
  st.info(
           "On remarque que 8 324 clients n'ont pas √©t√© contact√©s lors de la campagne pr√©c√©dente. \n"
           "Lorsque PREVIOUS = 0 alors PDAYS = -1")
  st.info(
           "Dans l'ordre, les variables les plus corr√©l√©es (valeur absolue) avec la target _[deposit]_ sont \n"
           "* **_duration_** = Dur√©e du contact (en secondes) \n"
           "* **_contact_** = Type de contact \n"
           "* housing = Pr√™t immo \n"
           "* previous = Nb contacts au cours de la campagne pr√©c√©dente \n"
           "* housing = pdays = Nb jours √©coul√©s depuis le dernier contact de la campagne pr√©c√©dente \n"
           "* previous = balance = Solde compte bancaire \n"
           "**Attention** , les **_deux variables_** correspondent √† des donn√©es non connues √† priori (avant lancement de la campagne)")
         
# ______________________________________________________________________________________________________
# 3/ Pr√©processing
# ______________________________________________________________________________________________________

if page==pages[2]: 

  st.title("Pr√©processing - Mod√®les pr√©dictifs")


# ---------- Le pr√©processing, √ßa sert √† quoi -----------

  expander1 = st.expander("Le pr√©processing, √ßa sert √† quoi ?")

  expander1.markdown(
           "Le pr√©processing est une de composante essentielle de la data science. "
           "Cette √©tape d√©crit toutes les **transformations** effectu√©es sur le jeu de donn√©es initial et indispensables √† la cr√©ation du mod√®le d'apprentissage fiable et robuste. "
           "Les algorithmes d'apprentissage automatique fonctionnent mieux lorsque les donn√©es sont pr√©sent√©es dans un format qui met en √©vidence les aspects pertinents requis pour r√©soudre un probl√®me. "
           "Les fonctions de pr√©processing consistent √† **restructurer** les donn√©es brutes sous une forme adapt√©e √† des types particuliers d'algorithmes. Les √©tapes sont : "
           "/n"
           "* la transformation des donn√©es, \n"
           "* la r√©duction des donn√©es, \n"
           "* la s√©lection des variables \n"
           "* et √† la mise √† l'√©chelle \n")
  
  expander1.image('preprocessing.JPG', caption='Les √©tapes de pr√©processing')     


# ---------- Les √©tapes de pr√©processing -----------

  st.header("Les √©tapes de pr√©processing appliqu√©es :")

# Variables num√©riques

  st.subheader("Le traitement des variables num√©riques")
  code = ''' 
    # Creation de tranches d'√¢ges
    df2['t_age'] = pd.cut(x = df2['age'], bins = [17, 30, 40, 50, 65, 96], labels = ['18-30', '30-40','40-50', '50-65','65-95'])

    # Creation de tranches de solde compte bancaire = balance
    df2['t_balance'] = pd.qcut(x=df2["balance"], q=4, labels=[1,2,3,4])

    # Creation de tranches de dur√©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de dur√©e de contact = duration
    df2['t_duration'] = pd.qcut(df2["duration"], q=4, labels=[1,2,3,4])

    # Creation de tranches de nombre de contact = campaign > Corrige le probl√®me de valeurs abb√©rantes et limite √† 4 contacts
    df2['t_campaign'] = pd.cut(x = df2['campaign'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Cr√©ation d'une cat√©gorie pour contact campagne pr√©c√©dente oui/non
    df2['contact_last_campaign'] = np.where(df2['pdays']>=0, 'yes', 'no')

    # Cr√©ation de tranches en fonction du d√©lai √©coul√©
    df2['t_pdays'] = pd.cut(x = df2['pdays'], bins = [-2, 0, 200, 999], labels = ['NON CONTACTE', 'MOINS DE 200J', 'PLUS DE 200J'])

    # Creation de tranches de nombre de contact avant la campagne
    df2['previous'] = pd.cut(x = df2['previous'], bins = [0, 1, 2, 3, 99], labels = [1, 2, 3, 4])

    # Suppression des colonnes dummies"√©es"
    drop_cols=['age','balance','duration','campaign','pdays','previous']
    df2 = df2.drop(drop_cols, axis=1)
    '''
  st.code(code, language='python')

# Variables cat√©gorielles

  st.subheader("Le traitement des variables cat√©gorielles")
  code = ''' 
    # Cr√©ation de dummies
    var=['marital','education','poutcome','contact','t_age','t_balance','t_duration','t_campaign','t_pdays','month']
    df2= df2.join(pd.get_dummies(df2[var], prefix=var))
    df2 = df2.drop(df2[var], axis=1)

    # Transformation en num√©rique
    le = LabelEncoder()
    df2['job2']= le.fit_transform(df2['job'])
    df2 = df2.drop(['job'], axis=1)

    # Remplace yes/no par 1/0
    var = ["default", "housing","loan","deposit","contact_last_campaign"]
    df2[var] = df2[var].replace(('yes', 'no'), (1, 0))
    '''
  st.code(code, language='python')

         
# ---------- Jeu de donn√©es final -----------

  st.header("Le jeu de donn√©es final :")
  st.write(df2)
         
# ---------- Arbre de correlations apr√®s preprocessing -----------

  st.header("Arbre de correlations apr√®s preprocessing :")

  fig = plt.figure(figsize=(20,8))
  df2.corr()['deposit'].sort_values().drop('deposit').plot(kind='bar', cmap='viridis')
  st.pyplot(fig)
         


# ---------- Les enseignements -----------

  st.header("Les observations :")
  st.info(
           "On voit clairement que la feature **[duration]** impacte positivement la campagne d√®s lors que la valeur est √©lev√©e (temps de contact)."
           "\n Egalement, les clients ayant r√©pondu favorablement √† la campagne pr√©c√©dente **[poutcome]** semblent √™tre les plus susceptibles de renouveler leur action."
           "\n Les mois de mars et octobre [month] semblent √™tre les meilleurs mois pour optimiser les leads.")


# ______________________________________________________________________________________________________
# 4/ Challenge de mod√®les
# ______________________________________________________________________________________________________

if page==pages[3]: 

  st.title("Mod√®les pr√©dictifs")
     

# ---------- Initialisation du jeu de donn√©es -----------

  df3=df2.copy()

# ---------- Split jeu entrainement et jeu de test -----------

  # Isoler les features de la target
  target = df3['deposit']
  feats = df3.drop(['deposit'], axis=1)

  # S√©paration des donn√©es en jeu d'entra√Ænement et de test
  from sklearn.model_selection import train_test_split
  X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25)

  # Normaliser les donn√©es - MinMaxScaler
  scaler = MinMaxScaler()
  X_train = scaler.fit_transform(X_train)
  X_test = scaler.transform(X_test)

  # Sauvegarde des r√©sulats de chacun des mod√®les
  models=[]
  scores =[]
  precision=[]
  rappel=[]
  roc=[]

# ---------- Les 3 mod√®les -----------

  col1, col2, col3, col4 = st.columns(4)

# R√©gression logistique -----------------------------------------------------------------------

  with col1:
    expander = st.expander("Mod√®le RLC")
    rlc = linear_model.LogisticRegression(C=10)
    rlc.fit(X_train, y_train)
        
    expander.metric("Score train", "{:.2%}".format(rlc.score(X_train, y_train)))
    expander.metric("Score test", "{:.2%}".format(rlc.score(X_test, y_test)))
    expander.metric("Precision Score", "{:.2%}".format(precision_score(y_test, rlc.predict(X_test))))

    y_pred = rlc.predict(X_test)
    expander.write("Matrice de confusion :")
    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("Regression logistique")
    scores.append(rlc.score(X_test, y_test))
    precision.append(precision_score(y_test, rlc.predict(X_test)))
    rappel.append(recall_score(y_test, rlc.predict(X_test)))
    roc.append(roc_auc_score(y_test, rlc.predict(X_test)))
    probs_rlc = rlc.predict_proba(X_test)

# K plus proche voisins -----------------------------------------------------------------------

  with col2:
    expander = st.expander("Mod√®le KNN")

    knn = neighbors.KNeighborsClassifier(n_neighbors=39)
    knn.fit(X_train, y_train)
      
    expander.metric("Score train", "{:.2%}".format(knn.score(X_train, y_train)))
    expander.metric("Score test", "{:.2%}".format(knn.score(X_test, y_test)))
    expander.metric("Precision Score", "{:.2%}".format(precision_score(y_test, knn.predict(X_test))))

    y_pred = knn.predict(X_test)
    expander.write("Matrice de confusion :")
    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("K plus proches voisins")
    scores.append(knn.score(X_test, y_test))
    precision.append(precision_score(y_test, knn.predict(X_test)))
    rappel.append(recall_score(y_test, knn.predict(X_test)))
    roc.append(roc_auc_score(y_test, knn.predict(X_test)))
    probs_knn = knn.predict_proba(X_test)

# Arbre de d√©cision -----------------------------------------------------------------------

  with col3:
    expander = st.expander("Mod√®le DTC")

    dtc = tree.DecisionTreeClassifier(max_depth=9)
    dtc.fit(X_train, y_train)  
        
    expander.metric("Score train", "{:.2%}".format(dtc.score(X_train, y_train)))
    expander.metric("Score test", "{:.2%}".format(dtc.score(X_test, y_test)))
    expander.metric("Precision Score", "{:.2%}".format(precision_score(y_test, dtc.predict(X_test))))

    y_pred = dtc.predict(X_test)
    expander.write("Matrice de confusion :")
    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("Decision Tree")
    scores.append(dtc.score(X_test, y_test))
    precision.append(precision_score(y_test, dtc.predict(X_test)))
    rappel.append(recall_score(y_test, dtc.predict(X_test)))
    roc.append(roc_auc_score(y_test, dtc.predict(X_test)))
    probs_dtc = dtc.predict_proba(X_test)

# Random Forest -----------------------------------------------------------------------

  with col4:
    expander = st.expander("Mod√®le RFC")

    rfc = ensemble.RandomForestClassifier(n_jobs=1) 
    rfc.fit(X_train, y_train)
    
    expander.metric("Score train", "{:.2%}".format(rfc.score(X_train, y_train)))
    expander.metric("Score test", "{:.2%}".format(rfc.score(X_test, y_test)))
    expander.metric("Precision Score", "{:.2%}".format(precision_score(y_test, rfc.predict(X_test))))

    y_pred = rfc.predict(X_test)
    expander.write("Matrice de confusion :")
    expander.write(pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite']))

    # Sauvegarde des r√©sultats
    models.append("Random Forest")
    scores.append(rfc.score(X_test, y_test))
    precision.append(precision_score(y_test, rfc.predict(X_test)))
    rappel.append(recall_score(y_test, rfc.predict(X_test)))
    roc.append(roc_auc_score(y_test, rfc.predict(X_test)))
    probs_rfc = rfc.predict_proba(X_test)


# Comparaison des r√©sultats -----------------------------------------------------------------------

  st.header("Comparaison des 4 mod√®les")

  # Recap des scores
  compare = pd.DataFrame(models)
  compare.columns = ['model']
  compare["accuracy"]=scores
  compare["precision"]=precision
  compare["rappel"]=rappel
  compare["roc"]=roc

  #Graphique de comparaison des r√©sultats     
  fig = plt.figure(figsize=(20,6))
  bar = px.bar(compare, x="model", y=['accuracy', 'precision', 'rappel','roc'], barmode='group')
  bar.add_hline(y=0.80, line_width=3, line_dash="dash", line_color="black")
  st.plotly_chart(bar)     

  # Comparaison avec l'indice des ROC
  fig = plt.figure(figsize=(20,10))

  # Regression logistique
  fpr, tpr, seuils = roc_curve(y_test, probs_rlc[:,1])
  roc_auc = auc(fpr, tpr)
  plt.plot(fpr, tpr, color='green', lw=2, label='Mod√®le RLC (auc = %0.2f)' % roc_auc)

  # K plus proches voisins
  fpr, tpr, seuils = roc_curve(y_test, probs_knn[:,1])
  roc_auc = auc(fpr, tpr)
  plt.plot(fpr, tpr, color='blue', lw=2, label='Mod√®le KNN (auc = %0.2f)' % roc_auc)

  # Decision Tree
  fpr, tpr, seuils = roc_curve(y_test, probs_dtc[:,1])
  roc_auc = auc(fpr, tpr)
  plt.plot(fpr, tpr, color='orange', lw=2, label='Mod√®le DTC (auc = %0.2f)' % roc_auc)

  # Random Forest
  fpr, tpr, seuils = roc_curve(y_test, probs_rfc[:,1])
  roc_auc = auc(fpr, tpr)
  plt.plot(fpr, tpr, color='red', lw=2, label='Mod√®le RFC (auc = %0.2f)' % roc_auc)

  plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Al√©atoire (auc = 0.5)')
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('Taux faux positifs')
  plt.ylabel('Taux vrais positifs')
  plt.title('Courbe ROC pour mod√®le Random Forest')
  plt.legend(loc="lower right")
  st.pyplot(fig)

  st.write("Le mod√®le Random Forest semble le plus √©quilibr√©. Il permet de maximiser les positifs.")
